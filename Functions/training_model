from keras.utils import to_categorical
from sklearn.utils import class_weight
from keras import callbacks
import multi_unet_model

def train_model(x_train, y_train, x_test, y_test, n_classes, crop_h, crop_w, n_channels, batch_size=8, epochs=10, early_stopping_patience=5, verbose=1):

    # Compute class weights
    class_weights = class_weight.compute_class_weight(class_weight ='balanced', classes=np.unique(y_train), y=y_train.reshape(-1,))
    
    # Prepare output data
    train_masks_cat = to_categorical(y_train, num_classes=n_classes)
    y_train_cat = train_masks_cat.reshape((y_train.shape[0], y_train.shape[1], y_train.shape[2], n_classes))
    
    test_masks_cat = to_categorical(y_test, num_classes=n_classes)
    y_test_cat = test_masks_cat.reshape((y_test.shape[0], y_test.shape[1], y_test.shape[2], n_classes))
    
    # Define callback for early stopping
    callback = callbacks.EarlyStopping(monitor='val_loss', patience=early_stopping_patience, restore_best_weights=True)
    
    # Create the model
    unet_model = multi_unet_model(n_classes=n_classes, IMG_HEIGHT=crop_h, IMG_WIDTH=crop_w, IMG_CHANNELS=n_channels)

    # Compile the model
    unet_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # Train the model
    history = unet_model.fit(x_train, y_train_cat,
                             batch_size=batch_size,
                             verbose=verbose,
                             epochs=epochs,
                             validation_data=(x_test, y_test_cat),
                             class_weight=class_weights,
                             shuffle=True,
                             callbacks=[callback])
    
    return history
